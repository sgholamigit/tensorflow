{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import tarfile\n",
    "from IPython.display import display, Image\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy import ndimage\n",
    "from six.moves import cPickle as pickle\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_filename = 'train14D6class10000'\n",
    "test_filename = 'train14D6class100'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train14D6class10000 already present - Skipping extraction of train14D6class10000.\n",
      "['train14D6class10000/0', 'train14D6class10000/100', 'train14D6class10000/150', 'train14D6class10000/200', 'train14D6class10000/250', 'train14D6class10000/50']\n",
      "train14D6class100 already present - Skipping extraction of train14D6class100.\n",
      "['train14D6class100/0', 'train14D6class100/100', 'train14D6class100/150', 'train14D6class100/200', 'train14D6class100/250', 'train14D6class100/50']\n"
     ]
    }
   ],
   "source": [
    "# extracting the datasets\n",
    "num_classes = 6\n",
    "np.random.seed(133)\n",
    "\n",
    "def maybe_extract(filename, force=False):\n",
    "  root = os.path.splitext(os.path.splitext(filename)[0])[0]  # remove .tar.gz\n",
    "  if os.path.isdir(root) and not force:\n",
    "    # You may override by setting force=True.\n",
    "    print('%s already present - Skipping extraction of %s.' % (root, filename))\n",
    "  else:\n",
    "    print('Extracting data for %s. This may take a while. Please wait.' % root)\n",
    "    tar = tarfile.open(filename)\n",
    "    sys.stdout.flush()\n",
    "    tar.extractall()\n",
    "    tar.close()\n",
    "  data_folders = [\n",
    "    os.path.join(root, d) for d in sorted(os.listdir(root))\n",
    "    if os.path.isdir(os.path.join(root, d))]\n",
    "  if len(data_folders) != num_classes:\n",
    "    raise Exception(\n",
    "      'Expected %d folders, one per class. Found %d instead.' % (\n",
    "        num_classes, len(data_folders)))\n",
    "  print(data_folders)\n",
    "  return data_folders\n",
    "  \n",
    "train_folders = maybe_extract(train_filename)\n",
    "test_folders = maybe_extract(test_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# have a look at data\n",
    "import random\n",
    "import hashlib\n",
    "\n",
    "def disp_samples(data_folders, sample_size):\n",
    "  for folder in data_folders:\n",
    "    print(folder)\n",
    "    image_files = os.listdir(folder)\n",
    "    image_sample = random.sample(image_files, sample_size)\n",
    "    for image in image_sample:\n",
    "      image_file = os.path.join(folder, image)\n",
    "      i = Image(filename=image_file)\n",
    "      display(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train14D6class10000/0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAEElEQVR4nGNgGAWjYBQQAwADLAAB\nPwpG8wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train14D6class10000/100\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAIUlEQVR4nGOMZMANmPDIjUrSUJLl\nNgq3bMAdNCrJwMAAAIf5AeSqf97hAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train14D6class10000/150\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAIUlEQVR4nGOcxoAbMOGRG5WkoSSj\nEwp3xYA7aFSSgYEBAJ7HAbf6yQ2RAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train14D6class10000/200\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAJElEQVR4nGP8wYAMbqHwmBjwgFFJ\n2kmyLEXhygy4g0YlGRgYAEe4As3E3RYjAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train14D6class10000/250\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAFklEQVR4nGP8xYAbMOGRG5UclRxh\nkgB0JwEy8y5bXAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train14D6class10000/50\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAJElEQVR4nGNkZUAG4ig8JgY8YFSS\ndpKMPSjc/gF30KgkAwMDAGnbAW5TOeuyAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "disp_samples(train_folders, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train14D6class100/0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAEElEQVR4nGNgGAWjYBQQAwADLAAB\nPwpG8wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train14D6class100/100\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAJElEQVR4nGNMZUAGGig8JgY8YFSS\ndpIsZ1G47APuoFFJBgYGAGrWAZtHW3D3AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train14D6class100/150\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAJElEQVR4nGOcxoAMbFF4TAx4wKgk\n7SRZ5FG46QPuoFFJBgYGAMbMAZM8Ssz0AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train14D6class100/200\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAJElEQVR4nGO8yYAMGFF4TAx4wKgk\n7SRZ3qNw7w64g0YlGRgYAN2pAuC2u7Z1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train14D6class100/250\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAFklEQVR4nGP8xYAbMOGRG5UclRxh\nkgB0JwEy8y5bXAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train14D6class100/50\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAJElEQVR4nGMMZEAGD1F4TAx4wKgk\n7SQZ1VC4PwfcQaOSDAwMANA2AohzpGXnAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "disp_samples(test_folders, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging train14D6class10000/0.\n",
      "Merging train14D6class10000/100.\n",
      "Merging train14D6class10000/150.\n",
      "Merging train14D6class10000/200.\n",
      "Merging train14D6class10000/250.\n",
      "Merging train14D6class10000/50.\n",
      "Merging train14D6class100/0.\n",
      "Merging train14D6class100/100.\n",
      "Merging train14D6class100/150.\n",
      "Merging train14D6class100/200.\n",
      "Merging train14D6class100/250.\n",
      "Merging train14D6class100/50.\n",
      "[[[  0.   0.   0. ...,   0.   0.   0.]\n",
      "  [  0.   0.   0. ...,   0.   0.   0.]\n",
      "  [  0.   0.   0. ...,   0.   0.   0.]\n",
      "  ..., \n",
      "  [  0.   0.   0. ...,   0.   0.   0.]\n",
      "  [  0.   0.   0. ...,   0.   0.   0.]\n",
      "  [  0.   0.   0. ...,   0.   0.   0.]]\n",
      "\n",
      " [[  0.   0.   0. ...,   0.   0.   0.]\n",
      "  [  0.   0.   0. ...,   0.   0.   0.]\n",
      "  [  0.   0.   0. ...,   0.   0.   0.]\n",
      "  ..., \n",
      "  [  0.   0.   0. ...,   0.   0.   0.]\n",
      "  [  0.   0.   0. ...,   0.   0.   0.]\n",
      "  [  0.   0.   0. ...,   0.   0.   0.]]\n",
      "\n",
      " [[  0.   0.   0. ...,   0.   0.   0.]\n",
      "  [  0.   0.   0. ...,   0.   0.   0.]\n",
      "  [  0.   0.   0. ...,   0.   0.   0.]\n",
      "  ..., \n",
      "  [  0.   0.   0. ...,   0.   0.   0.]\n",
      "  [  0.   0.   0. ...,   0.   0.   0.]\n",
      "  [  0.   0.   0. ...,   0.   0.   0.]]\n",
      "\n",
      " ..., \n",
      " [[ 77.  77.  77. ...,   4.   4.   4.]\n",
      "  [ 77.  77.  77. ...,   4.   4.   4.]\n",
      "  [ 77.  77.  77. ...,   4.   4.   4.]\n",
      "  ..., \n",
      "  [ 82.  82.  82. ...,  37.  37.  37.]\n",
      "  [ 82.  82.  82. ...,  37.  37.  37.]\n",
      "  [ 82.  82.  82. ...,  37.  37.  37.]]\n",
      "\n",
      " [[ 50.  50.  50. ...,  50.  50.  50.]\n",
      "  [ 50.  50.  50. ...,  50.  50.  50.]\n",
      "  [ 50.  50.  50. ...,  50.  50.  50.]\n",
      "  ..., \n",
      "  [ 50.  50.  50. ...,  50.  50.  50.]\n",
      "  [ 50.  50.  50. ...,  50.  50.  50.]\n",
      "  [ 50.  50.  50. ...,  50.  50.  50.]]\n",
      "\n",
      " [[ 64.  64.  64. ...,   3.   3.   3.]\n",
      "  [ 64.  64.  64. ...,   3.   3.   3.]\n",
      "  [ 64.  64.  64. ...,   3.   3.   3.]\n",
      "  ..., \n",
      "  [ 43.  43.  43. ...,  90.  90.  90.]\n",
      "  [ 43.  43.  43. ...,  90.  90.  90.]\n",
      "  [ 43.  43.  43. ...,  90.  90.  90.]]]\n",
      "[[ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " ..., \n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]]\n",
      "[[[   0.    0.    0. ...,    0.    0.    0.]\n",
      "  [   0.    0.    0. ...,    0.    0.    0.]\n",
      "  [   0.    0.    0. ...,    0.    0.    0.]\n",
      "  ..., \n",
      "  [   0.    0.    0. ...,    0.    0.    0.]\n",
      "  [   0.    0.    0. ...,    0.    0.    0.]\n",
      "  [   0.    0.    0. ...,    0.    0.    0.]]\n",
      "\n",
      " [[   0.    0.    0. ...,    0.    0.    0.]\n",
      "  [   0.    0.    0. ...,    0.    0.    0.]\n",
      "  [   0.    0.    0. ...,    0.    0.    0.]\n",
      "  ..., \n",
      "  [   0.    0.    0. ...,    0.    0.    0.]\n",
      "  [   0.    0.    0. ...,    0.    0.    0.]\n",
      "  [   0.    0.    0. ...,    0.    0.    0.]]\n",
      "\n",
      " [[   0.    0.    0. ...,    0.    0.    0.]\n",
      "  [   0.    0.    0. ...,    0.    0.    0.]\n",
      "  [   0.    0.    0. ...,    0.    0.    0.]\n",
      "  ..., \n",
      "  [   0.    0.    0. ...,    0.    0.    0.]\n",
      "  [   0.    0.    0. ...,    0.    0.    0.]\n",
      "  [   0.    0.    0. ...,    0.    0.    0.]]\n",
      "\n",
      " ..., \n",
      " [[  37.   37.   37. ...,   14.   14.   14.]\n",
      "  [  37.   37.   37. ...,   14.   14.   14.]\n",
      "  [  37.   37.   37. ...,   14.   14.   14.]\n",
      "  ..., \n",
      "  [  36.   36.   36. ...,  113.  113.  113.]\n",
      "  [  36.   36.   36. ...,  113.  113.  113.]\n",
      "  [  36.   36.   36. ...,  113.  113.  113.]]\n",
      "\n",
      " [[  32.   32.   32. ...,   23.   23.   23.]\n",
      "  [  32.   32.   32. ...,   23.   23.   23.]\n",
      "  [  32.   32.   32. ...,   23.   23.   23.]\n",
      "  ..., \n",
      "  [   4.    4.    4. ...,  141.  141.  141.]\n",
      "  [   4.    4.    4. ...,  141.  141.  141.]\n",
      "  [   4.    4.    4. ...,  141.  141.  141.]]\n",
      "\n",
      " [[  81.   81.   81. ...,   50.   50.   50.]\n",
      "  [  81.   81.   81. ...,   50.   50.   50.]\n",
      "  [  81.   81.   81. ...,   50.   50.   50.]\n",
      "  ..., \n",
      "  [  38.   38.   38. ...,   31.   31.   31.]\n",
      "  [  38.   38.   38. ...,   31.   31.   31.]\n",
      "  [  38.   38.   38. ...,   31.   31.   31.]]]\n",
      "[[ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.39215687]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.58823532]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.78431374]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.98039216]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]\n",
      " [ 0.19607843]]\n",
      "trainDataset.shape (60000, 28, 28)\n",
      "labelsTrainDataset.shape (60000, 1)\n",
      "testDataset.shape (600, 28, 28)\n",
      "labelsTestDataset.shape (600, 1)\n"
     ]
    }
   ],
   "source": [
    "#Merging the data\n",
    "\n",
    "image_size = 28  # Pixel width and height.\n",
    "pixel_depth = 255.0  # Number of levels per pixel.\n",
    "num_of_classes = 6\n",
    "\n",
    "float_formatter = lambda x: \"%.2f\" % x\n",
    "\n",
    "        \n",
    "def Merge_folders(data_folders, size_per_class):\n",
    "  dataset_names = []\n",
    "  start_t = 0\n",
    "  end_t = size_per_class\n",
    "  required_size = size_per_class * num_of_classes\n",
    "  trainDataset = np.ndarray((required_size, image_size, image_size), dtype=np.float32)\n",
    "  labelsDataset = np.ndarray((required_size, 1), dtype=np.float32)\n",
    "  for folder in data_folders:\n",
    "    dataset_names.append(folder)\n",
    "\n",
    "    print('Merging %s.' % folder)\n",
    "    image_files = os.listdir(folder)\n",
    "    dataset = np.ndarray(shape=(len(image_files), image_size, image_size),\n",
    "                         dtype=np.float32)\n",
    "    image_index = 0\n",
    "    for image in os.listdir(folder):\n",
    "        if image_index < size_per_class:\n",
    "            image_file = os.path.join(folder, image)\n",
    "            image_data = (ndimage.imread(image_file).astype(int))\n",
    "            dataset[image_index, :, :] = image_data\n",
    "            image_index += 1\n",
    "    num_images = image_index\n",
    "    dataset = dataset[0:num_images, :, :]\n",
    "    trainDataset[start_t:end_t, :, :] = dataset\n",
    "    x = float(folder.split(\"/\")[1]) / 255.0\n",
    "    #y = float_formatter(x)\n",
    "    labelsDataset[start_t:end_t] = x\n",
    "    start_t += size_per_class\n",
    "    end_t += size_per_class\n",
    "\n",
    "  \n",
    "  return dataset_names, trainDataset, labelsDataset\n",
    "\n",
    "train_datasets, trainDataset, labelsTrainDataset = Merge_folders(train_folders, 10000)\n",
    "test_datasets, testDataset, labelsTestDataset = Merge_folders(test_folders, 100)\n",
    "\n",
    "print(trainDataset)\n",
    "print(labelsTrainDataset)\n",
    "\n",
    "print(testDataset)\n",
    "print(labelsTestDataset)\n",
    "\n",
    "print('trainDataset.shape' , trainDataset.shape)\n",
    "print('labelsTrainDataset.shape' , labelsTrainDataset.shape)\n",
    "\n",
    "print('testDataset.shape' , testDataset.shape)\n",
    "print('labelsTestDataset.shape' , labelsTestDataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23352\n",
      "[ 0.58823532]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWEAAAFfCAYAAACfj30KAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\no/AitAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc813e32290>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.58823529411764708"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test the data\n",
    "rand_image = random.randint(0, 60000)\n",
    "print (rand_image)\n",
    "plt.imshow(trainDataset[rand_image], cmap='gray', interpolation='nearest', vmin=0, vmax=255)\n",
    "print (labelsTrainDataset[rand_image])\n",
    "plt.show()\n",
    "np.mean(trainDataset[rand_image])/ 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# randomize the data\n",
    "def randomize(dataset, labels):\n",
    "  permutation = np.random.permutation(labels.shape[0])\n",
    "  shuffled_dataset = dataset[permutation,:,:]\n",
    "  shuffled_labels = labels[permutation]\n",
    "  return shuffled_dataset, shuffled_labels\n",
    "train_dataset, train_labels = randomize(trainDataset, labelsTrainDataset)\n",
    "test_dataset, test_labels = randomize(testDataset, labelsTestDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53462\n",
      "[ 0.78431374]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWEAAAFfCAYAAACfj30KAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqdD/AbHgQ3nFQl+QAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc813b2e610>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.78431372549019607"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test the data\n",
    "rand_image = random.randint(0, 60000)\n",
    "print (rand_image)\n",
    "plt.imshow(train_dataset[rand_image], cmap='gray', interpolation='nearest', vmin=0, vmax=255)\n",
    "print (train_labels[rand_image])\n",
    "plt.show()\n",
    "np.mean(train_dataset[rand_image]) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69\n",
      "[ 0.19607843]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWEAAAFfCAYAAACfj30KAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGWFJKmSEJamQEZakQkZYkgoZYUkq9H/VpzHfEdBvXgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc813a24d90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.19607843137254902"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test the data\n",
    "rand_image = random.randint(0, 600)\n",
    "print (rand_image)\n",
    "plt.imshow(test_dataset[rand_image], cmap='gray', interpolation='nearest', vmin=0, vmax=255)\n",
    "print (test_labels[rand_image])\n",
    "plt.show()\n",
    "np.mean(test_dataset[rand_image]) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the data\n",
    "pickle_file = 'br6class14DReg.pickle'\n",
    "\n",
    "try:\n",
    "  f = open(pickle_file, 'wb')\n",
    "  save = {\n",
    "    'train_dataset': train_dataset,\n",
    "    'train_labels': train_labels,\n",
    "    'test_dataset': test_dataset,\n",
    "    'test_labels': test_labels,\n",
    "    }\n",
    "  pickle.dump(save, f, pickle.HIGHEST_PROTOCOL)\n",
    "  f.close()\n",
    "except Exception as e:\n",
    "  print('Unable to save data to', pickle_file, ':', e)\n",
    "  raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressed pickle size: 190284307\n"
     ]
    }
   ],
   "source": [
    "statinfo = os.stat(pickle_file)\n",
    "print('Compressed pickle size:', statinfo.st_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26739\n"
     ]
    }
   ],
   "source": [
    "#estimate the duplicates\n",
    "\n",
    "all_data = pickle.load(open('br6class14DReg.pickle', 'rb'))\n",
    "\n",
    "def count_duplicates(dataset1, dataset2):\n",
    "    hashes = [hashlib.sha1(x).hexdigest() for x in dataset1]\n",
    "    dup_indices = []\n",
    "    for i in range(0, len(dataset2)):\n",
    "        if hashlib.sha1(dataset2[i]).hexdigest() in hashes:\n",
    "            dup_indices.append(i)\n",
    "    return len(dup_indices)\n",
    "\n",
    "\n",
    "print(count_duplicates(all_data['test_dataset'], all_data['train_dataset']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "60000\n",
      "600\n",
      "600\n"
     ]
    }
   ],
   "source": [
    "# test a regression model\n",
    "\n",
    "train_dataset = all_data['train_dataset']\n",
    "train_labels = all_data['train_labels']\n",
    "test_dataset = all_data['test_dataset']\n",
    "test_labels = all_data['test_labels']\n",
    "\n",
    "print (len(train_dataset))\n",
    "print (len(train_labels))\n",
    "print (len(test_dataset))\n",
    "print (len(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 trainsamples score: 1.0\n",
      "1000 trainsamples score: 1.0\n",
      "5000 trainsamples score: 1.0\n",
      "10000 trainsamples score: 1.0\n",
      "60000 trainsamples score: 1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_score(train_dataset, train_labels, test_dataset, test_labels):\n",
    "    model = LinearRegression()\n",
    "    train_flatten_dataset = np.array([x.flatten() for x in train_dataset])\n",
    "    test_flatten_dataset = np.array([x.flatten() for x in test_dataset])\n",
    "    model.fit(train_flatten_dataset, train_labels)\n",
    "\n",
    "    return model.score([x.flatten() for x in test_dataset], test_labels)\n",
    "\n",
    "print(\"100 trainsamples score: \" + str(get_score(train_dataset[:100], train_labels[:100], test_dataset, test_labels)))\n",
    "print(\"1000 trainsamples score: \" + str(get_score(train_dataset[:1000], train_labels[:1000], test_dataset, test_labels)))\n",
    "print(\"5000 trainsamples score: \" + str(get_score(train_dataset[:5000], train_labels[:5000], test_dataset, test_labels)))\n",
    "print(\"10000 trainsamples score: \" + str(get_score(train_dataset[:10000], train_labels[:10000], test_dataset, test_labels)))\n",
    "print(\"60000 trainsamples score: \" + str(get_score(train_dataset[:60000], train_labels[:60000], test_dataset, test_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 0.00\n",
      "Variance score: 1.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "regr = linear_model.LinearRegression()\n",
    "train_flatten_dataset = np.array([x.flatten() for x in train_dataset])\n",
    "test_flatten_dataset = np.array([x.flatten() for x in test_dataset])\n",
    "regr.fit(train_flatten_dataset, train_labels)\n",
    "print(\"Mean squared error: %.2f\"\n",
    "      % np.mean((regr.predict(test_flatten_dataset) - test_labels) ** 2))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % regr.score(test_flatten_dataset, test_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  56.,   56.,   56., ...,   99.,   99.,   99.],\n",
       "       [   0.,    0.,    0., ...,    0.,    0.,    0.],\n",
       "       [ 188.,  188.,  188., ...,   76.,   76.,   76.],\n",
       "       ..., \n",
       "       [   0.,    0.,    0., ...,    0.,    0.,    0.],\n",
       "       [  21.,   21.,   21., ...,   80.,   80.,   80.],\n",
       "       [ 200.,  200.,  200., ...,  236.,  236.,  236.]], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_flatten_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.39215687],\n",
       "       [ 0.        ],\n",
       "       [ 0.58823532],\n",
       "       [ 0.        ],\n",
       "       [ 0.39215687],\n",
       "       [ 0.78431374],\n",
       "       [ 0.19607843],\n",
       "       [ 0.19607843],\n",
       "       [ 0.98039216],\n",
       "       [ 0.        ],\n",
       "       [ 0.98039216],\n",
       "       [ 0.19607843],\n",
       "       [ 0.98039216],\n",
       "       [ 0.        ],\n",
       "       [ 0.58823532],\n",
       "       [ 0.98039216],\n",
       "       [ 0.19607843],\n",
       "       [ 0.98039216],\n",
       "       [ 0.39215687],\n",
       "       [ 0.19607843],\n",
       "       [ 0.        ],\n",
       "       [ 0.78431374],\n",
       "       [ 0.        ],\n",
       "       [ 0.78431374],\n",
       "       [ 0.58823532],\n",
       "       [ 0.        ],\n",
       "       [ 0.98039216],\n",
       "       [ 0.98039216],\n",
       "       [ 0.39215687],\n",
       "       [ 0.19607843],\n",
       "       [ 0.39215687],\n",
       "       [ 0.39215687],\n",
       "       [ 0.39215687],\n",
       "       [ 0.39215687],\n",
       "       [ 0.        ],\n",
       "       [ 0.98039216],\n",
       "       [ 0.39215687],\n",
       "       [ 0.39215687],\n",
       "       [ 0.58823532],\n",
       "       [ 0.19607843],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.19607843],\n",
       "       [ 0.58823532],\n",
       "       [ 0.58823532],\n",
       "       [ 0.58823532],\n",
       "       [ 0.58823532],\n",
       "       [ 0.58823532],\n",
       "       [ 0.        ],\n",
       "       [ 0.98039216],\n",
       "       [ 0.19607843],\n",
       "       [ 0.19607843],\n",
       "       [ 0.78431374],\n",
       "       [ 0.19607843],\n",
       "       [ 0.        ],\n",
       "       [ 0.58823532],\n",
       "       [ 0.39215687],\n",
       "       [ 0.58823532],\n",
       "       [ 0.78431374],\n",
       "       [ 0.98039216],\n",
       "       [ 0.19607843],\n",
       "       [ 0.39215687],\n",
       "       [ 0.19607843],\n",
       "       [ 0.98039216],\n",
       "       [ 0.58823532],\n",
       "       [ 0.98039216],\n",
       "       [ 0.19607843],\n",
       "       [ 0.39215687],\n",
       "       [ 0.39215687],\n",
       "       [ 0.19607843],\n",
       "       [ 0.19607843],\n",
       "       [ 0.58823532],\n",
       "       [ 0.98039216],\n",
       "       [ 0.58823532],\n",
       "       [ 0.39215687],\n",
       "       [ 0.78431374],\n",
       "       [ 0.58823532],\n",
       "       [ 0.19607843],\n",
       "       [ 0.78431374],\n",
       "       [ 0.98039216],\n",
       "       [ 0.19607843],\n",
       "       [ 0.78431374],\n",
       "       [ 0.39215687],\n",
       "       [ 0.58823532],\n",
       "       [ 0.98039216],\n",
       "       [ 0.78431374],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.19607843],\n",
       "       [ 0.98039216],\n",
       "       [ 0.78431374],\n",
       "       [ 0.19607843],\n",
       "       [ 0.98039216],\n",
       "       [ 0.98039216],\n",
       "       [ 0.78431374],\n",
       "       [ 0.39215687],\n",
       "       [ 0.19607843],\n",
       "       [ 0.58823532],\n",
       "       [ 0.78431374],\n",
       "       [ 0.98039216],\n",
       "       [ 0.98039216],\n",
       "       [ 0.39215687],\n",
       "       [ 0.19607843],\n",
       "       [ 0.98039216],\n",
       "       [ 0.19607843],\n",
       "       [ 0.58823532],\n",
       "       [ 0.78431374],\n",
       "       [ 0.58823532],\n",
       "       [ 0.58823532],\n",
       "       [ 0.        ],\n",
       "       [ 0.78431374],\n",
       "       [ 0.19607843],\n",
       "       [ 0.98039216],\n",
       "       [ 0.        ],\n",
       "       [ 0.58823532],\n",
       "       [ 0.98039216],\n",
       "       [ 0.58823532],\n",
       "       [ 0.19607843],\n",
       "       [ 0.19607843],\n",
       "       [ 0.58823532],\n",
       "       [ 0.        ],\n",
       "       [ 0.78431374],\n",
       "       [ 0.19607843],\n",
       "       [ 0.39215687],\n",
       "       [ 0.78431374],\n",
       "       [ 0.        ],\n",
       "       [ 0.78431374],\n",
       "       [ 0.        ],\n",
       "       [ 0.19607843],\n",
       "       [ 0.19607843],\n",
       "       [ 0.39215687],\n",
       "       [ 0.98039216],\n",
       "       [ 0.78431374],\n",
       "       [ 0.        ],\n",
       "       [ 0.58823532],\n",
       "       [ 0.19607843],\n",
       "       [ 0.58823532],\n",
       "       [ 0.78431374],\n",
       "       [ 0.39215687],\n",
       "       [ 0.39215687],\n",
       "       [ 0.78431374],\n",
       "       [ 0.98039216],\n",
       "       [ 0.39215687],\n",
       "       [ 0.78431374],\n",
       "       [ 0.98039216],\n",
       "       [ 0.58823532],\n",
       "       [ 0.19607843],\n",
       "       [ 0.58823532],\n",
       "       [ 0.78431374],\n",
       "       [ 0.39215687],\n",
       "       [ 0.78431374],\n",
       "       [ 0.39215687],\n",
       "       [ 0.98039216],\n",
       "       [ 0.98039216],\n",
       "       [ 0.        ],\n",
       "       [ 0.78431374],\n",
       "       [ 0.        ],\n",
       "       [ 0.39215687],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.39215687],\n",
       "       [ 0.98039216],\n",
       "       [ 0.39215687],\n",
       "       [ 0.98039216],\n",
       "       [ 0.39215687],\n",
       "       [ 0.39215687],\n",
       "       [ 0.58823532],\n",
       "       [ 0.78431374],\n",
       "       [ 0.        ],\n",
       "       [ 0.98039216],\n",
       "       [ 0.78431374],\n",
       "       [ 0.19607843],\n",
       "       [ 0.78431374],\n",
       "       [ 0.39215687],\n",
       "       [ 0.78431374],\n",
       "       [ 0.39215687],\n",
       "       [ 0.39215687],\n",
       "       [ 0.        ],\n",
       "       [ 0.98039216],\n",
       "       [ 0.58823532],\n",
       "       [ 0.98039216],\n",
       "       [ 0.        ],\n",
       "       [ 0.58823532],\n",
       "       [ 0.19607843],\n",
       "       [ 0.19607843],\n",
       "       [ 0.78431374],\n",
       "       [ 0.58823532],\n",
       "       [ 0.98039216],\n",
       "       [ 0.        ],\n",
       "       [ 0.58823532],\n",
       "       [ 0.78431374],\n",
       "       [ 0.39215687],\n",
       "       [ 0.78431374],\n",
       "       [ 0.58823532],\n",
       "       [ 0.        ],\n",
       "       [ 0.39215687],\n",
       "       [ 0.        ],\n",
       "       [ 0.19607843],\n",
       "       [ 0.39215687],\n",
       "       [ 0.39215687],\n",
       "       [ 0.19607843],\n",
       "       [ 0.58823532],\n",
       "       [ 0.98039216],\n",
       "       [ 0.        ],\n",
       "       [ 0.78431374],\n",
       "       [ 0.39215687],\n",
       "       [ 0.58823532],\n",
       "       [ 0.58823532],\n",
       "       [ 0.58823532],\n",
       "       [ 0.78431374],\n",
       "       [ 0.98039216],\n",
       "       [ 0.58823532],\n",
       "       [ 0.39215687],\n",
       "       [ 0.        ],\n",
       "       [ 0.78431374],\n",
       "       [ 0.58823532],\n",
       "       [ 0.39215687],\n",
       "       [ 0.        ],\n",
       "       [ 0.19607843],\n",
       "       [ 0.39215687],\n",
       "       [ 0.19607843],\n",
       "       [ 0.58823532],\n",
       "       [ 0.        ],\n",
       "       [ 0.98039216],\n",
       "       [ 0.19607843],\n",
       "       [ 0.19607843],\n",
       "       [ 0.19607843],\n",
       "       [ 0.19607843],\n",
       "       [ 0.78431374],\n",
       "       [ 0.        ],\n",
       "       [ 0.58823532],\n",
       "       [ 0.39215687],\n",
       "       [ 0.58823532],\n",
       "       [ 0.78431374],\n",
       "       [ 0.58823532],\n",
       "       [ 0.        ],\n",
       "       [ 0.98039216],\n",
       "       [ 0.98039216],\n",
       "       [ 0.78431374],\n",
       "       [ 0.19607843],\n",
       "       [ 0.78431374],\n",
       "       [ 0.58823532],\n",
       "       [ 0.19607843],\n",
       "       [ 0.78431374],\n",
       "       [ 0.58823532],\n",
       "       [ 0.78431374],\n",
       "       [ 0.58823532],\n",
       "       [ 0.39215687],\n",
       "       [ 0.98039216],\n",
       "       [ 0.78431374],\n",
       "       [ 0.78431374],\n",
       "       [ 0.78431374],\n",
       "       [ 0.        ],\n",
       "       [ 0.98039216],\n",
       "       [ 0.39215687],\n",
       "       [ 0.78431374],\n",
       "       [ 0.19607843],\n",
       "       [ 0.98039216],\n",
       "       [ 0.98039216],\n",
       "       [ 0.58823532],\n",
       "       [ 0.19607843],\n",
       "       [ 0.39215687],\n",
       "       [ 0.58823532],\n",
       "       [ 0.58823532],\n",
       "       [ 0.78431374],\n",
       "       [ 0.39215687],\n",
       "       [ 0.        ],\n",
       "       [ 0.39215687],\n",
       "       [ 0.39215687],\n",
       "       [ 0.        ],\n",
       "       [ 0.98039216],\n",
       "       [ 0.58823532],\n",
       "       [ 0.78431374],\n",
       "       [ 0.        ],\n",
       "       [ 0.19607843],\n",
       "       [ 0.98039216],\n",
       "       [ 0.78431374],\n",
       "       [ 0.78431374],\n",
       "       [ 0.        ],\n",
       "       [ 0.19607843],\n",
       "       [ 0.78431374],\n",
       "       [ 0.98039216],\n",
       "       [ 0.19607843],\n",
       "       [ 0.        ],\n",
       "       [ 0.39215687],\n",
       "       [ 0.78431374],\n",
       "       [ 0.78431374],\n",
       "       [ 0.58823532],\n",
       "       [ 0.78431374],\n",
       "       [ 0.        ],\n",
       "       [ 0.39215687],\n",
       "       [ 0.78431374],\n",
       "       [ 0.98039216],\n",
       "       [ 0.19607843],\n",
       "       [ 0.78431374],\n",
       "       [ 0.        ],\n",
       "       [ 0.39215687],\n",
       "       [ 0.        ],\n",
       "       [ 0.39215687],\n",
       "       [ 0.98039216],\n",
       "       [ 0.98039216],\n",
       "       [ 0.78431374],\n",
       "       [ 0.39215687],\n",
       "       [ 0.        ],\n",
       "       [ 0.98039216],\n",
       "       [ 0.39215687],\n",
       "       [ 0.78431374],\n",
       "       [ 0.78431374],\n",
       "       [ 0.98039216],\n",
       "       [ 0.        ],\n",
       "       [ 0.58823532],\n",
       "       [ 0.98039216],\n",
       "       [ 0.98039216],\n",
       "       [ 0.39215687],\n",
       "       [ 0.78431374],\n",
       "       [ 0.        ],\n",
       "       [ 0.78431374],\n",
       "       [ 0.58823532],\n",
       "       [ 0.19607843],\n",
       "       [ 0.19607843],\n",
       "       [ 0.39215687],\n",
       "       [ 0.39215687],\n",
       "       [ 0.39215687],\n",
       "       [ 0.98039216],\n",
       "       [ 0.39215687],\n",
       "       [ 0.        ],\n",
       "       [ 0.19607843],\n",
       "       [ 0.78431374],\n",
       "       [ 0.78431374],\n",
       "       [ 0.19607843],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.19607843],\n",
       "       [ 0.        ],\n",
       "       [ 0.58823532],\n",
       "       [ 0.98039216],\n",
       "       [ 0.98039216],\n",
       "       [ 0.78431374],\n",
       "       [ 0.58823532],\n",
       "       [ 0.39215687],\n",
       "       [ 0.98039216],\n",
       "       [ 0.78431374],\n",
       "       [ 0.39215687],\n",
       "       [ 0.98039216],\n",
       "       [ 0.19607843],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.39215687],\n",
       "       [ 0.98039216],\n",
       "       [ 0.58823532],\n",
       "       [ 0.39215687],\n",
       "       [ 0.58823532],\n",
       "       [ 0.98039216],\n",
       "       [ 0.        ],\n",
       "       [ 0.98039216],\n",
       "       [ 0.39215687],\n",
       "       [ 0.39215687],\n",
       "       [ 0.39215687],\n",
       "       [ 0.39215687],\n",
       "       [ 0.39215687],\n",
       "       [ 0.39215687],\n",
       "       [ 0.19607843],\n",
       "       [ 0.58823532],\n",
       "       [ 0.        ],\n",
       "       [ 0.19607843],\n",
       "       [ 0.39215687],\n",
       "       [ 0.98039216],\n",
       "       [ 0.78431374],\n",
       "       [ 0.78431374],\n",
       "       [ 0.98039216],\n",
       "       [ 0.19607843],\n",
       "       [ 0.        ],\n",
       "       [ 0.39215687],\n",
       "       [ 0.19607843],\n",
       "       [ 0.98039216],\n",
       "       [ 0.98039216],\n",
       "       [ 0.58823532],\n",
       "       [ 0.58823532],\n",
       "       [ 0.58823532],\n",
       "       [ 0.58823532],\n",
       "       [ 0.39215687],\n",
       "       [ 0.        ],\n",
       "       [ 0.39215687],\n",
       "       [ 0.19607843],\n",
       "       [ 0.        ],\n",
       "       [ 0.39215687],\n",
       "       [ 0.58823532],\n",
       "       [ 0.98039216],\n",
       "       [ 0.        ],\n",
       "       [ 0.78431374],\n",
       "       [ 0.78431374],\n",
       "       [ 0.98039216],\n",
       "       [ 0.        ],\n",
       "       [ 0.58823532],\n",
       "       [ 0.58823532],\n",
       "       [ 0.78431374],\n",
       "       [ 0.        ],\n",
       "       [ 0.98039216],\n",
       "       [ 0.19607843],\n",
       "       [ 0.78431374],\n",
       "       [ 0.        ],\n",
       "       [ 0.78431374],\n",
       "       [ 0.78431374],\n",
       "       [ 0.78431374],\n",
       "       [ 0.19607843],\n",
       "       [ 0.58823532],\n",
       "       [ 0.39215687],\n",
       "       [ 0.        ],\n",
       "       [ 0.19607843],\n",
       "       [ 0.        ],\n",
       "       [ 0.78431374],\n",
       "       [ 0.19607843],\n",
       "       [ 0.98039216],\n",
       "       [ 0.78431374],\n",
       "       [ 0.19607843],\n",
       "       [ 0.58823532],\n",
       "       [ 0.98039216],\n",
       "       [ 0.19607843],\n",
       "       [ 0.58823532],\n",
       "       [ 0.19607843],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.39215687],\n",
       "       [ 0.58823532],\n",
       "       [ 0.98039216],\n",
       "       [ 0.58823532],\n",
       "       [ 0.58823532],\n",
       "       [ 0.98039216],\n",
       "       [ 0.19607843],\n",
       "       [ 0.58823532],\n",
       "       [ 0.        ],\n",
       "       [ 0.39215687],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.39215687],\n",
       "       [ 0.98039216],\n",
       "       [ 0.39215687],\n",
       "       [ 0.98039216],\n",
       "       [ 0.98039216],\n",
       "       [ 0.19607843],\n",
       "       [ 0.19607843],\n",
       "       [ 0.        ],\n",
       "       [ 0.78431374],\n",
       "       [ 0.19607843],\n",
       "       [ 0.58823532],\n",
       "       [ 0.        ],\n",
       "       [ 0.39215687],\n",
       "       [ 0.98039216],\n",
       "       [ 0.58823532],\n",
       "       [ 0.98039216],\n",
       "       [ 0.98039216],\n",
       "       [ 0.        ],\n",
       "       [ 0.19607843],\n",
       "       [ 0.39215687],\n",
       "       [ 0.78431374],\n",
       "       [ 0.        ],\n",
       "       [ 0.78431374],\n",
       "       [ 0.78431374],\n",
       "       [ 0.        ],\n",
       "       [ 0.19607843],\n",
       "       [ 0.78431374],\n",
       "       [ 0.39215687],\n",
       "       [ 0.58823532],\n",
       "       [ 0.78431374],\n",
       "       [ 0.58823532],\n",
       "       [ 0.39215687],\n",
       "       [ 0.98039216],\n",
       "       [ 0.98039216],\n",
       "       [ 0.19607843],\n",
       "       [ 0.19607843],\n",
       "       [ 0.98039216],\n",
       "       [ 0.98039216],\n",
       "       [ 0.78431374],\n",
       "       [ 0.58823532],\n",
       "       [ 0.        ],\n",
       "       [ 0.58823532],\n",
       "       [ 0.19607843],\n",
       "       [ 0.39215687],\n",
       "       [ 0.58823532],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.19607843],\n",
       "       [ 0.39215687],\n",
       "       [ 0.        ],\n",
       "       [ 0.19607843],\n",
       "       [ 0.58823532],\n",
       "       [ 0.19607843],\n",
       "       [ 0.39215687],\n",
       "       [ 0.58823532],\n",
       "       [ 0.39215687],\n",
       "       [ 0.58823532],\n",
       "       [ 0.19607843],\n",
       "       [ 0.58823532],\n",
       "       [ 0.58823532],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.19607843],\n",
       "       [ 0.98039216],\n",
       "       [ 0.        ],\n",
       "       [ 0.        ],\n",
       "       [ 0.98039216],\n",
       "       [ 0.        ],\n",
       "       [ 0.98039216],\n",
       "       [ 0.        ],\n",
       "       [ 0.19607843],\n",
       "       [ 0.        ],\n",
       "       [ 0.98039216],\n",
       "       [ 0.39215687],\n",
       "       [ 0.78431374],\n",
       "       [ 0.58823532],\n",
       "       [ 0.58823532],\n",
       "       [ 0.19607843],\n",
       "       [ 0.58823532],\n",
       "       [ 0.98039216],\n",
       "       [ 0.98039216],\n",
       "       [ 0.        ],\n",
       "       [ 0.98039216],\n",
       "       [ 0.58823532],\n",
       "       [ 0.19607843],\n",
       "       [ 0.        ],\n",
       "       [ 0.98039216],\n",
       "       [ 0.39215687],\n",
       "       [ 0.39215687],\n",
       "       [ 0.98039216],\n",
       "       [ 0.58823532],\n",
       "       [ 0.        ],\n",
       "       [ 0.19607843],\n",
       "       [ 0.58823532],\n",
       "       [ 0.        ],\n",
       "       [ 0.19607843],\n",
       "       [ 0.19607843],\n",
       "       [ 0.19607843],\n",
       "       [ 0.78431374],\n",
       "       [ 0.        ],\n",
       "       [ 0.39215687],\n",
       "       [ 0.19607843],\n",
       "       [ 0.78431374],\n",
       "       [ 0.39215687],\n",
       "       [ 0.78431374],\n",
       "       [ 0.98039216],\n",
       "       [ 0.        ],\n",
       "       [ 0.78431374],\n",
       "       [ 0.58823532],\n",
       "       [ 0.58823532],\n",
       "       [ 0.        ],\n",
       "       [ 0.78431374],\n",
       "       [ 0.        ],\n",
       "       [ 0.39215687],\n",
       "       [ 0.58823532],\n",
       "       [ 0.19607843],\n",
       "       [ 0.19607843],\n",
       "       [ 0.        ],\n",
       "       [ 0.78431374],\n",
       "       [ 0.78431374],\n",
       "       [ 0.98039216],\n",
       "       [ 0.58823532],\n",
       "       [ 0.78431374],\n",
       "       [ 0.19607843],\n",
       "       [ 0.39215687],\n",
       "       [ 0.19607843],\n",
       "       [ 0.78431374],\n",
       "       [ 0.78431374],\n",
       "       [ 0.        ],\n",
       "       [ 0.78431374],\n",
       "       [ 0.19607843],\n",
       "       [ 0.58823532],\n",
       "       [ 0.19607843],\n",
       "       [ 0.39215687],\n",
       "       [ 0.39215687],\n",
       "       [ 0.19607843],\n",
       "       [ 0.39215687],\n",
       "       [ 0.78431374],\n",
       "       [ 0.78431374],\n",
       "       [ 0.39215687],\n",
       "       [ 0.58823532],\n",
       "       [ 0.19607843],\n",
       "       [ 0.98039216],\n",
       "       [ 0.98039216],\n",
       "       [ 0.98039216],\n",
       "       [ 0.78431374],\n",
       "       [ 0.98039216],\n",
       "       [ 0.19607843],\n",
       "       [ 0.58823532],\n",
       "       [ 0.58823532],\n",
       "       [ 0.58823532],\n",
       "       [ 0.78431374],\n",
       "       [ 0.        ],\n",
       "       [ 0.39215687],\n",
       "       [ 0.98039216],\n",
       "       [ 0.98039216],\n",
       "       [ 0.39215687],\n",
       "       [ 0.98039216],\n",
       "       [ 0.58823532],\n",
       "       [ 0.78431374],\n",
       "       [ 0.78431374],\n",
       "       [ 0.        ],\n",
       "       [ 0.19607843],\n",
       "       [ 0.78431374]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.3926704 ],\n",
       "       [ 0.00117126],\n",
       "       [ 0.58788774],\n",
       "       [ 0.00117126],\n",
       "       [ 0.39257011],\n",
       "       [ 0.78361076],\n",
       "       [ 0.19668533],\n",
       "       [ 0.19678113],\n",
       "       [ 0.97922063],\n",
       "       [ 0.00117126],\n",
       "       [ 0.97922063],\n",
       "       [ 0.19678018],\n",
       "       [ 0.97922063],\n",
       "       [ 0.00117126],\n",
       "       [ 0.58807208],\n",
       "       [ 0.97922063],\n",
       "       [ 0.19681343],\n",
       "       [ 0.97922063],\n",
       "       [ 0.39220353],\n",
       "       [ 0.19693181],\n",
       "       [ 0.00117126],\n",
       "       [ 0.78361076],\n",
       "       [ 0.00117126],\n",
       "       [ 0.78351019],\n",
       "       [ 0.58766279],\n",
       "       [ 0.00117126],\n",
       "       [ 0.97922063],\n",
       "       [ 0.97922063],\n",
       "       [ 0.39221769],\n",
       "       [ 0.19678113],\n",
       "       [ 0.3922771 ],\n",
       "       [ 0.39230587],\n",
       "       [ 0.39224328],\n",
       "       [ 0.3923458 ],\n",
       "       [ 0.00117126],\n",
       "       [ 0.97922063],\n",
       "       [ 0.3923881 ],\n",
       "       [ 0.39253693],\n",
       "       [ 0.58797074],\n",
       "       [ 0.19667356],\n",
       "       [ 0.00117126],\n",
       "       [ 0.00117126],\n",
       "       [ 0.19679815],\n",
       "       [ 0.58818346],\n",
       "       [ 0.58827242],\n",
       "       [ 0.58800088],\n",
       "       [ 0.58800089],\n",
       "       [ 0.58824933],\n",
       "       [ 0.00117126],\n",
       "       [ 0.97921221],\n",
       "       [ 0.19683082],\n",
       "       [ 0.19676208],\n",
       "       [ 0.78361076],\n",
       "       [ 0.1969733 ],\n",
       "       [ 0.00117126],\n",
       "       [ 0.58823291],\n",
       "       [ 0.3923501 ],\n",
       "       [ 0.58802004],\n",
       "       [ 0.78361076],\n",
       "       [ 0.97922909],\n",
       "       [ 0.19680243],\n",
       "       [ 0.39222186],\n",
       "       [ 0.19691157],\n",
       "       [ 0.97922063],\n",
       "       [ 0.58837777],\n",
       "       [ 0.97922063],\n",
       "       [ 0.19694435],\n",
       "       [ 0.39243277],\n",
       "       [ 0.39245482],\n",
       "       [ 0.19687124],\n",
       "       [ 0.19682   ],\n",
       "       [ 0.58781352],\n",
       "       [ 0.97922063],\n",
       "       [ 0.58807967],\n",
       "       [ 0.39261703],\n",
       "       [ 0.78371731],\n",
       "       [ 0.58808343],\n",
       "       [ 0.19661519],\n",
       "       [ 0.78333081],\n",
       "       [ 0.97922063],\n",
       "       [ 0.19667267],\n",
       "       [ 0.78361076],\n",
       "       [ 0.39220281],\n",
       "       [ 0.58828805],\n",
       "       [ 0.97922063],\n",
       "       [ 0.78361076],\n",
       "       [ 0.00117126],\n",
       "       [ 0.00117126],\n",
       "       [ 0.19678113],\n",
       "       [ 0.97922063],\n",
       "       [ 0.78361076],\n",
       "       [ 0.19670654],\n",
       "       [ 0.97922063],\n",
       "       [ 0.97922063],\n",
       "       [ 0.78361076],\n",
       "       [ 0.39238986],\n",
       "       [ 0.19701463],\n",
       "       [ 0.58775191],\n",
       "       [ 0.78361076],\n",
       "       [ 0.97923647],\n",
       "       [ 0.97922063],\n",
       "       [ 0.39253798],\n",
       "       [ 0.19682241],\n",
       "       [ 0.97922063],\n",
       "       [ 0.19658443],\n",
       "       [ 0.58813706],\n",
       "       [ 0.78352374],\n",
       "       [ 0.58805788],\n",
       "       [ 0.58800088],\n",
       "       [ 0.00117126],\n",
       "       [ 0.78348507],\n",
       "       [ 0.19695013],\n",
       "       [ 0.97922063],\n",
       "       [ 0.00117126],\n",
       "       [ 0.58784306],\n",
       "       [ 0.97922063],\n",
       "       [ 0.58761203],\n",
       "       [ 0.19694087],\n",
       "       [ 0.19678113],\n",
       "       [ 0.58794915],\n",
       "       [ 0.00117126],\n",
       "       [ 0.78379954],\n",
       "       [ 0.19680512],\n",
       "       [ 0.39239526],\n",
       "       [ 0.78374016],\n",
       "       [ 0.00117126],\n",
       "       [ 0.78346817],\n",
       "       [ 0.00117126],\n",
       "       [ 0.19688571],\n",
       "       [ 0.19687942],\n",
       "       [ 0.39269252],\n",
       "       [ 0.97922063],\n",
       "       [ 0.78360976],\n",
       "       [ 0.00117126],\n",
       "       [ 0.58800088],\n",
       "       [ 0.19685071],\n",
       "       [ 0.58824903],\n",
       "       [ 0.7836376 ],\n",
       "       [ 0.39221484],\n",
       "       [ 0.39237002],\n",
       "       [ 0.78361057],\n",
       "       [ 0.97922063],\n",
       "       [ 0.39252159],\n",
       "       [ 0.78366673],\n",
       "       [ 0.97922063],\n",
       "       [ 0.58803949],\n",
       "       [ 0.19683707],\n",
       "       [ 0.5883765 ],\n",
       "       [ 0.78382675],\n",
       "       [ 0.39216825],\n",
       "       [ 0.78382182],\n",
       "       [ 0.39228401],\n",
       "       [ 0.97922063],\n",
       "       [ 0.97922063],\n",
       "       [ 0.00117126],\n",
       "       [ 0.78357927],\n",
       "       [ 0.00117126],\n",
       "       [ 0.39232072],\n",
       "       [ 0.00117126],\n",
       "       [ 0.00117126],\n",
       "       [ 0.39219509],\n",
       "       [ 0.97922063],\n",
       "       [ 0.39251297],\n",
       "       [ 0.97922063],\n",
       "       [ 0.39262959],\n",
       "       [ 0.39263126],\n",
       "       [ 0.58816751],\n",
       "       [ 0.78361611],\n",
       "       [ 0.00117126],\n",
       "       [ 0.97922063],\n",
       "       [ 0.78361076],\n",
       "       [ 0.19662752],\n",
       "       [ 0.78344302],\n",
       "       [ 0.39202855],\n",
       "       [ 0.7836419 ],\n",
       "       [ 0.39219903],\n",
       "       [ 0.39263972],\n",
       "       [ 0.00117126],\n",
       "       [ 0.97921853],\n",
       "       [ 0.58799708],\n",
       "       [ 0.97922063],\n",
       "       [ 0.00117126],\n",
       "       [ 0.58780268],\n",
       "       [ 0.19673552],\n",
       "       [ 0.19661332],\n",
       "       [ 0.78364023],\n",
       "       [ 0.58839151],\n",
       "       [ 0.97922063],\n",
       "       [ 0.00117126],\n",
       "       [ 0.58777887],\n",
       "       [ 0.78348847],\n",
       "       [ 0.39232433],\n",
       "       [ 0.78361076],\n",
       "       [ 0.58810391],\n",
       "       [ 0.00117126],\n",
       "       [ 0.39228589],\n",
       "       [ 0.00117126],\n",
       "       [ 0.1968737 ],\n",
       "       [ 0.39234343],\n",
       "       [ 0.39258254],\n",
       "       [ 0.19685248],\n",
       "       [ 0.58824814],\n",
       "       [ 0.97922063],\n",
       "       [ 0.00117126],\n",
       "       [ 0.78361076],\n",
       "       [ 0.39229588],\n",
       "       [ 0.58804651],\n",
       "       [ 0.58821409],\n",
       "       [ 0.58773298],\n",
       "       [ 0.78357337],\n",
       "       [ 0.97922063],\n",
       "       [ 0.58800088],\n",
       "       [ 0.39218643],\n",
       "       [ 0.00117126],\n",
       "       [ 0.78371313],\n",
       "       [ 0.58781511],\n",
       "       [ 0.39237458],\n",
       "       [ 0.00117126],\n",
       "       [ 0.19704596],\n",
       "       [ 0.39253123],\n",
       "       [ 0.19673966],\n",
       "       [ 0.5882397 ],\n",
       "       [ 0.00117126],\n",
       "       [ 0.97922063],\n",
       "       [ 0.19686805],\n",
       "       [ 0.19657196],\n",
       "       [ 0.19673839],\n",
       "       [ 0.19666828],\n",
       "       [ 0.78349328],\n",
       "       [ 0.00117126],\n",
       "       [ 0.58800088],\n",
       "       [ 0.39246995],\n",
       "       [ 0.588015  ],\n",
       "       [ 0.78372328],\n",
       "       [ 0.58800088],\n",
       "       [ 0.00117126],\n",
       "       [ 0.97922063],\n",
       "       [ 0.97922063],\n",
       "       [ 0.78368736],\n",
       "       [ 0.19678113],\n",
       "       [ 0.78361076],\n",
       "       [ 0.58800088],\n",
       "       [ 0.19674457],\n",
       "       [ 0.78373644],\n",
       "       [ 0.58827174],\n",
       "       [ 0.78361076],\n",
       "       [ 0.58783981],\n",
       "       [ 0.39239101],\n",
       "       [ 0.97922063],\n",
       "       [ 0.78361076],\n",
       "       [ 0.78365838],\n",
       "       [ 0.78358694],\n",
       "       [ 0.00117126],\n",
       "       [ 0.97922063],\n",
       "       [ 0.39230376],\n",
       "       [ 0.78361076],\n",
       "       [ 0.19684255],\n",
       "       [ 0.97922063],\n",
       "       [ 0.97922063],\n",
       "       [ 0.58788989],\n",
       "       [ 0.19671337],\n",
       "       [ 0.39221843],\n",
       "       [ 0.58795659],\n",
       "       [ 0.58800088],\n",
       "       [ 0.78369132],\n",
       "       [ 0.39265899],\n",
       "       [ 0.00117126],\n",
       "       [ 0.39233803],\n",
       "       [ 0.39275367],\n",
       "       [ 0.00117126],\n",
       "       [ 0.97922063],\n",
       "       [ 0.58763867],\n",
       "       [ 0.78364607],\n",
       "       [ 0.00117126],\n",
       "       [ 0.1966713 ],\n",
       "       [ 0.97922063],\n",
       "       [ 0.78361076],\n",
       "       [ 0.78361076],\n",
       "       [ 0.00117126],\n",
       "       [ 0.19680712],\n",
       "       [ 0.78361137],\n",
       "       [ 0.97922063],\n",
       "       [ 0.19694203],\n",
       "       [ 0.00117126],\n",
       "       [ 0.39269056],\n",
       "       [ 0.78378488],\n",
       "       [ 0.78367489],\n",
       "       [ 0.58800088],\n",
       "       [ 0.78369445],\n",
       "       [ 0.00117126],\n",
       "       [ 0.39244998],\n",
       "       [ 0.78361076],\n",
       "       [ 0.97922063],\n",
       "       [ 0.19680281],\n",
       "       [ 0.78354715],\n",
       "       [ 0.00117126],\n",
       "       [ 0.39217509],\n",
       "       [ 0.00117126],\n",
       "       [ 0.39238676],\n",
       "       [ 0.97922063],\n",
       "       [ 0.97922063],\n",
       "       [ 0.78345393],\n",
       "       [ 0.3922744 ],\n",
       "       [ 0.00117126],\n",
       "       [ 0.97922063],\n",
       "       [ 0.392421  ],\n",
       "       [ 0.78374297],\n",
       "       [ 0.78361076],\n",
       "       [ 0.97922063],\n",
       "       [ 0.00117126],\n",
       "       [ 0.58800088],\n",
       "       [ 0.97922063],\n",
       "       [ 0.97922063],\n",
       "       [ 0.39236514],\n",
       "       [ 0.78361076],\n",
       "       [ 0.00117126],\n",
       "       [ 0.78361076],\n",
       "       [ 0.58779144],\n",
       "       [ 0.19678328],\n",
       "       [ 0.19678458],\n",
       "       [ 0.39204187],\n",
       "       [ 0.39232382],\n",
       "       [ 0.39252775],\n",
       "       [ 0.97922063],\n",
       "       [ 0.39256608],\n",
       "       [ 0.00117126],\n",
       "       [ 0.19660068],\n",
       "       [ 0.78344771],\n",
       "       [ 0.78346147],\n",
       "       [ 0.19712669],\n",
       "       [ 0.00117126],\n",
       "       [ 0.00117126],\n",
       "       [ 0.00117126],\n",
       "       [ 0.00117126],\n",
       "       [ 0.19679701],\n",
       "       [ 0.00117126],\n",
       "       [ 0.58791969],\n",
       "       [ 0.97922063],\n",
       "       [ 0.97922063],\n",
       "       [ 0.78336623],\n",
       "       [ 0.58814332],\n",
       "       [ 0.39230113],\n",
       "       [ 0.97922063],\n",
       "       [ 0.78371071],\n",
       "       [ 0.39234132],\n",
       "       [ 0.97922063],\n",
       "       [ 0.19668991],\n",
       "       [ 0.00117126],\n",
       "       [ 0.00117126],\n",
       "       [ 0.39231834],\n",
       "       [ 0.97922063],\n",
       "       [ 0.58824709],\n",
       "       [ 0.39227095],\n",
       "       [ 0.58827405],\n",
       "       [ 0.97920776],\n",
       "       [ 0.00117126],\n",
       "       [ 0.97922909],\n",
       "       [ 0.39239101],\n",
       "       [ 0.39217218],\n",
       "       [ 0.39236222],\n",
       "       [ 0.39212964],\n",
       "       [ 0.39249235],\n",
       "       [ 0.39258533],\n",
       "       [ 0.19670475],\n",
       "       [ 0.58806121],\n",
       "       [ 0.00117126],\n",
       "       [ 0.19687024],\n",
       "       [ 0.39214218],\n",
       "       [ 0.97922063],\n",
       "       [ 0.78350678],\n",
       "       [ 0.78361076],\n",
       "       [ 0.97922063],\n",
       "       [ 0.19679847],\n",
       "       [ 0.00117126],\n",
       "       [ 0.392696  ],\n",
       "       [ 0.19665465],\n",
       "       [ 0.97922063],\n",
       "       [ 0.97922063],\n",
       "       [ 0.58756622],\n",
       "       [ 0.58789078],\n",
       "       [ 0.5879883 ],\n",
       "       [ 0.58770671],\n",
       "       [ 0.3924928 ],\n",
       "       [ 0.00117126],\n",
       "       [ 0.39237173],\n",
       "       [ 0.19682835],\n",
       "       [ 0.00117126],\n",
       "       [ 0.39233116],\n",
       "       [ 0.58818192],\n",
       "       [ 0.97922063],\n",
       "       [ 0.00117126],\n",
       "       [ 0.78350109],\n",
       "       [ 0.78340636],\n",
       "       [ 0.97921752],\n",
       "       [ 0.00117126],\n",
       "       [ 0.58821623],\n",
       "       [ 0.58847232],\n",
       "       [ 0.78341663],\n",
       "       [ 0.00117126],\n",
       "       [ 0.97922063],\n",
       "       [ 0.1965687 ],\n",
       "       [ 0.78361076],\n",
       "       [ 0.00117126],\n",
       "       [ 0.78361204],\n",
       "       [ 0.78361076],\n",
       "       [ 0.78361076],\n",
       "       [ 0.19697108],\n",
       "       [ 0.5880073 ],\n",
       "       [ 0.39213018],\n",
       "       [ 0.00117126],\n",
       "       [ 0.19669836],\n",
       "       [ 0.00117126],\n",
       "       [ 0.78361076],\n",
       "       [ 0.19678113],\n",
       "       [ 0.97922063],\n",
       "       [ 0.78350896],\n",
       "       [ 0.19677643],\n",
       "       [ 0.58800088],\n",
       "       [ 0.97922063],\n",
       "       [ 0.19667278],\n",
       "       [ 0.58804222],\n",
       "       [ 0.19684767],\n",
       "       [ 0.00117126],\n",
       "       [ 0.00117126],\n",
       "       [ 0.39223778],\n",
       "       [ 0.5881055 ],\n",
       "       [ 0.97922063],\n",
       "       [ 0.58800088],\n",
       "       [ 0.58800088],\n",
       "       [ 0.97922063],\n",
       "       [ 0.19680007],\n",
       "       [ 0.58780561],\n",
       "       [ 0.00117126],\n",
       "       [ 0.39273595],\n",
       "       [ 0.00117126],\n",
       "       [ 0.00117126],\n",
       "       [ 0.39239208],\n",
       "       [ 0.97922063],\n",
       "       [ 0.39226936],\n",
       "       [ 0.97922063],\n",
       "       [ 0.97922063],\n",
       "       [ 0.19687517],\n",
       "       [ 0.19675209],\n",
       "       [ 0.00117126],\n",
       "       [ 0.78361076],\n",
       "       [ 0.1971171 ],\n",
       "       [ 0.58793455],\n",
       "       [ 0.00117126],\n",
       "       [ 0.39213957],\n",
       "       [ 0.97922929],\n",
       "       [ 0.58821553],\n",
       "       [ 0.97922063],\n",
       "       [ 0.97922063],\n",
       "       [ 0.00117126],\n",
       "       [ 0.19668935],\n",
       "       [ 0.39228143],\n",
       "       [ 0.7835455 ],\n",
       "       [ 0.00117126],\n",
       "       [ 0.78361076],\n",
       "       [ 0.78361076],\n",
       "       [ 0.00117126],\n",
       "       [ 0.19692586],\n",
       "       [ 0.78378508],\n",
       "       [ 0.39236638],\n",
       "       [ 0.58821638],\n",
       "       [ 0.78361076],\n",
       "       [ 0.58798465],\n",
       "       [ 0.39229433],\n",
       "       [ 0.97922063],\n",
       "       [ 0.97922063],\n",
       "       [ 0.19677927],\n",
       "       [ 0.1966537 ],\n",
       "       [ 0.97922063],\n",
       "       [ 0.97922063],\n",
       "       [ 0.78361076],\n",
       "       [ 0.58771654],\n",
       "       [ 0.00117126],\n",
       "       [ 0.5877747 ],\n",
       "       [ 0.19685372],\n",
       "       [ 0.39239101],\n",
       "       [ 0.58783148],\n",
       "       [ 0.00117126],\n",
       "       [ 0.00117126],\n",
       "       [ 0.19690643],\n",
       "       [ 0.39222552],\n",
       "       [ 0.00117126],\n",
       "       [ 0.19664464],\n",
       "       [ 0.5880569 ],\n",
       "       [ 0.19678113],\n",
       "       [ 0.39239101],\n",
       "       [ 0.58800088],\n",
       "       [ 0.39254522],\n",
       "       [ 0.58799188],\n",
       "       [ 0.19673258],\n",
       "       [ 0.58800088],\n",
       "       [ 0.58808563],\n",
       "       [ 0.00117126],\n",
       "       [ 0.00117126],\n",
       "       [ 0.19690413],\n",
       "       [ 0.97922063],\n",
       "       [ 0.00117126],\n",
       "       [ 0.00117126],\n",
       "       [ 0.97922063],\n",
       "       [ 0.00117126],\n",
       "       [ 0.97922063],\n",
       "       [ 0.00117126],\n",
       "       [ 0.19674241],\n",
       "       [ 0.00117126],\n",
       "       [ 0.97922063],\n",
       "       [ 0.39266448],\n",
       "       [ 0.78361076],\n",
       "       [ 0.58821262],\n",
       "       [ 0.58800088],\n",
       "       [ 0.19662179],\n",
       "       [ 0.58797811],\n",
       "       [ 0.97922063],\n",
       "       [ 0.97921206],\n",
       "       [ 0.00117126],\n",
       "       [ 0.97922063],\n",
       "       [ 0.58828726],\n",
       "       [ 0.19678113],\n",
       "       [ 0.00117126],\n",
       "       [ 0.97922281],\n",
       "       [ 0.39276862],\n",
       "       [ 0.3922706 ],\n",
       "       [ 0.97922063],\n",
       "       [ 0.58767234],\n",
       "       [ 0.00117126],\n",
       "       [ 0.19679415],\n",
       "       [ 0.58801006],\n",
       "       [ 0.00117126],\n",
       "       [ 0.1969072 ],\n",
       "       [ 0.19661103],\n",
       "       [ 0.19681102],\n",
       "       [ 0.78354296],\n",
       "       [ 0.00117126],\n",
       "       [ 0.39244023],\n",
       "       [ 0.19674047],\n",
       "       [ 0.78361076],\n",
       "       [ 0.3926346 ],\n",
       "       [ 0.78361076],\n",
       "       [ 0.97922997],\n",
       "       [ 0.00117126],\n",
       "       [ 0.78363331],\n",
       "       [ 0.58800197],\n",
       "       [ 0.58812486],\n",
       "       [ 0.00117126],\n",
       "       [ 0.78339142],\n",
       "       [ 0.00117126],\n",
       "       [ 0.39260016],\n",
       "       [ 0.58807306],\n",
       "       [ 0.19688783],\n",
       "       [ 0.19668468],\n",
       "       [ 0.00117126],\n",
       "       [ 0.78385306],\n",
       "       [ 0.78359342],\n",
       "       [ 0.97922063],\n",
       "       [ 0.58783057],\n",
       "       [ 0.78361718],\n",
       "       [ 0.19689274],\n",
       "       [ 0.39223816],\n",
       "       [ 0.19674923],\n",
       "       [ 0.78342004],\n",
       "       [ 0.78360123],\n",
       "       [ 0.00117126],\n",
       "       [ 0.78348726],\n",
       "       [ 0.19692556],\n",
       "       [ 0.5882663 ],\n",
       "       [ 0.1967441 ],\n",
       "       [ 0.39211559],\n",
       "       [ 0.3924094 ],\n",
       "       [ 0.19680306],\n",
       "       [ 0.39234563],\n",
       "       [ 0.7838387 ],\n",
       "       [ 0.78354981],\n",
       "       [ 0.39265552],\n",
       "       [ 0.58790408],\n",
       "       [ 0.19674479],\n",
       "       [ 0.97922063],\n",
       "       [ 0.97922063],\n",
       "       [ 0.97922063],\n",
       "       [ 0.78367801],\n",
       "       [ 0.97922063],\n",
       "       [ 0.19690262],\n",
       "       [ 0.58804298],\n",
       "       [ 0.58794468],\n",
       "       [ 0.58800088],\n",
       "       [ 0.78350382],\n",
       "       [ 0.00117126],\n",
       "       [ 0.39239101],\n",
       "       [ 0.97922063],\n",
       "       [ 0.97922063],\n",
       "       [ 0.39230306],\n",
       "       [ 0.97922063],\n",
       "       [ 0.58816948],\n",
       "       [ 0.78351221],\n",
       "       [ 0.78361076],\n",
       "       [ 0.00117126],\n",
       "       [ 0.19696314],\n",
       "       [ 0.78348333]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs = regr.predict(test_flatten_dataset)\n",
    "regr.predict(test_flatten_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 1)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 1)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr.predict(test_flatten_dataset).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.98039216],\n",
       "       [ 0.19607843],\n",
       "       [ 0.98039216],\n",
       "       [ 0.        ],\n",
       "       [ 0.58823532],\n",
       "       [ 0.98039216],\n",
       "       [ 0.19607843],\n",
       "       [ 0.98039216],\n",
       "       [ 0.39215687],\n",
       "       [ 0.19607843]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels[10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.97922063],\n",
       "       [ 0.19678018],\n",
       "       [ 0.97922063],\n",
       "       [ 0.00117126],\n",
       "       [ 0.58807208],\n",
       "       [ 0.97922063],\n",
       "       [ 0.19681343],\n",
       "       [ 0.97922063],\n",
       "       [ 0.39220353],\n",
       "       [ 0.19693181]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs[10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (60000, 28, 28) (60000, 1)\n",
      "Test set (600, 28, 28) (600, 1)\n"
     ]
    }
   ],
   "source": [
    "pickle_file = 'br6class14DReg.pickle'\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "  save = pickle.load(f)\n",
    "  train_dataset = save['train_dataset']\n",
    "  train_labels = save['train_labels']\n",
    "  test_dataset = save['test_dataset']\n",
    "  test_labels = save['test_labels']\n",
    "  del save  # hint to help gc free up memory\n",
    "  print('Training set', train_dataset.shape, train_labels.shape)\n",
    "  print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (60000, 784) (60000, 1)\n",
      "Test set (600, 784) (600, 1)\n"
     ]
    }
   ],
   "source": [
    "image_size = 28\n",
    "num_labels = 6\n",
    "\n",
    "def reformat(dataset, labels):\n",
    "  dataset = dataset.reshape((-1, image_size * image_size)).astype(np.float32)\n",
    "  # Map 0 to [1.0, 0.0, 0.0 ...], 1 to [0.0, 1.0, 0.0 ...]\n",
    "  return dataset, labels\n",
    "train_dataset, train_labels = reformat(train_dataset, train_labels)\n",
    "test_dataset, test_labels = reformat(test_dataset, test_labels)\n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# With gradient descent training, even this much data is prohibitive.\n",
    "# Subset the training data for faster turnaround.\n",
    "train_subset = 100\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data.\n",
    "  # Load the training, validation and test data into constants that are\n",
    "  # attached to the graph.\n",
    "  tf_train_dataset = tf.constant(train_dataset[:train_subset, :])\n",
    "  tf_train_labels = tf.constant(train_labels[:train_subset])\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  \n",
    "  # Variables.\n",
    "  # These are the parameters that we are going to be training. The weight\n",
    "  # matrix will be initialized using random valued following a (truncated)\n",
    "  # normal distribution. The biases get initialized to zero.\n",
    "  weights = tf.Variable(\n",
    "    tf.truncated_normal([image_size * image_size, 1]))\n",
    "  biases = tf.Variable(tf.zeros([1]))\n",
    "  \n",
    "  # Training computation.\n",
    "  # We multiply the inputs with the weight matrix, and add biases. We compute\n",
    "  # the softmax and cross-entropy (it's one operation in TensorFlow, because\n",
    "  # it's very common, and it can be optimized). We take the average of this\n",
    "  # cross-entropy across all training examples: that's our loss.\n",
    "  logits = tf.matmul(tf_train_dataset, weights) + biases\n",
    "  loss = tf.reduce_mean(tf.square(logits - tf_train_labels))\n",
    "  \n",
    "  # Optimizer.\n",
    "  # We are going to find the minimum of this loss using gradient descent.\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "  \n",
    "  # Predictions for the training, validation, and test data.\n",
    "  # These are not part of training, but merely here so that we can report\n",
    "  # accuracy figures as we train.\n",
    "  train_prediction = logits\n",
    "  test_prediction = tf.matmul(tf_test_dataset, weights) + biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Loss at step 0: 6314187.500000\n",
      "Loss at step 50: nan\n",
      "Loss at step 100: nan\n",
      "Loss at step 150: nan\n",
      "Loss at step 200: nan\n",
      "Loss at step 250: nan\n",
      "Loss at step 300: nan\n",
      "Loss at step 350: nan\n",
      "Loss at step 400: nan\n",
      "Loss at step 450: nan\n",
      "Loss at step 500: nan\n",
      "Loss at step 550: nan\n",
      "Loss at step 600: nan\n",
      "Loss at step 650: nan\n",
      "Loss at step 700: nan\n",
      "Loss at step 750: nan\n",
      "Loss at step 800: nan\n",
      "Loss at step 850: nan\n",
      "Loss at step 900: nan\n",
      "Loss at step 950: nan\n",
      "Loss at step 1000: nan\n"
     ]
    }
   ],
   "source": [
    "def meanSqrError(predictions, values):\n",
    "  return np.mean(((predictions - values) ** 2))\n",
    "\n",
    "num_steps = 1001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.global_variables_initializer().run()\n",
    "  print('Initialized')\n",
    "  for step in range(num_steps):\n",
    "    #feed_dict = {tf_train_dataset : tf_train_dataset, tf_train_labels : tf_train_labels}\n",
    "    #_, l, predictions = session.run(\n",
    "    #  [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    _, l, predictions = session.run([optimizer, loss, train_prediction])\n",
    "    #tuning_cost = session.run(loss, feed_dict)\n",
    "    #print (\"Tuning cost=\", \"{:.9f}\".format(tuning_cost))\n",
    "    if (step % 50 == 0):\n",
    "        print('Loss at step %d: %f' % (step, l))\n",
    "      #print('Minibatch loss at step %d: %f' % (step, tuning_cost))\n",
    "  #print('Test accuracy: %.1f%%' % meanSqrError(test_prediction.eval(), test_prediction))\n",
    "  #testing_cost = session.run(loss, feed_dict={tf_test_dataset: tf_test_dataset, test_labels:test_labels})    \n",
    "  #print (\"Testing data cost:\" , testing_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
